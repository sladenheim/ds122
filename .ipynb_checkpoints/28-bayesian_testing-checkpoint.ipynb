{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Bayesian Testing & Decision Making\n",
        "author: \"CDS DS-122<br>Boston University\"\n",
        "format:\n",
        "    revealjs:\n",
        "        math: true\n",
        "        css:\n",
        "        - styles.css\n",
        "        html-math-method: mathjax\n",
        "        highlight-style: github\n",
        "        slide-number: true\n",
        "        show-slide-number: all\n",
        "        chalkboard: true\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import binom, randint\n",
        "from IPython.core.display import HTML\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning Objectives\n",
        ":::{style=\"font-size: .8em\"}\n",
        "\n",
        "- Understanding Bayes factors for hypothesis testing\n",
        "- Applying Bayesian hypothesis testing to the Euro problem\n",
        "- Using posterior predictive distributions for decision-making\n",
        "- Implementing Thompson sampling for the multi-armed bandit problem\n",
        "\n",
        ":::\n",
        "\n",
        "## The Euro Problem - Reminder\n",
        "\n",
        ":::{style=\"font-size: .7em\"}\n",
        "\n",
        "\n",
        "From David MacKay's _Information Theory, Inference, and Learning Algorithms_:\n",
        "\n",
        "> A statistical statement appeared in _The Guardian_ on Friday, January 4, 2002:\n",
        ">\n",
        "> \"When spun on edge 250 times, a Belgian one-euro coin came up heads 140 times and tails 110. 'It looks very suspicious to me,' said Barry Blight, a statistics lecturer at the London School of Economics. 'If the coin were unbiased, the chance of getting a result as extreme as that would be less than 7%.'\"\n",
        "\n",
        "**Question:** Do these data give evidence that the coin is biased rather than fair?\n",
        "\n",
        ":::\n",
        "\n",
        "## The Frequentist Answer\n",
        "\n",
        ":::{style=\"font-size: .8em\"}\n",
        "\n",
        "We can compute the p-value: the probability of observing data this extreme if the coin were fair.\n",
        "\n",
        "Under the null hypothesis ($p = 0.5$), the number of heads follows a binomial distribution. We want:\n",
        "\n",
        "$$p\\text{-value} = P(X \\geq 140) + P(X \\leq 110) $$\n",
        "\n",
        "$$= \\sum_{k=140}^{250} \\binom{250}{k} (0.5)^{250} + \\sum_{k=0}^{110} \\binom{250}{k} (0.5)^{250} = 0.0664$$\n",
        "\n",
        "So indeed, \"if the coin were unbiased, the chance of getting a result as extreme as that would be less than 7%.\"\n",
        "\n",
        "**But what's the Bayesian answer?**\n",
        "\n",
        ":::\n",
        "\n",
        "## Bayesian Estimate for p\n",
        "\n",
        ":::{style=\"font-size: .7em\"}\n",
        "\n",
        "Previously, we estimated the probability of heads, $p$, using Bayesian updating:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "def update(distribution, likelihood):\n",
        "    '''Standard Bayesian update function'''\n",
        "    distribution['probs'] = distribution['probs'] * likelihood\n",
        "    prob_data = distribution['probs'].sum()\n",
        "    distribution['probs'] = distribution['probs'] / prob_data\n",
        "    return distribution\n",
        "\n",
        "# Start with uniform prior\n",
        "p_dist = pd.DataFrame(index=np.arange(101)/100)\n",
        "p_dist['probs'] = 1/101  # uniform\n",
        "\n",
        "# Compute likelihood: 140 heads in 250 flips\n",
        "likelihood = [binom.pmf(140, 250, p) for p in p_dist.index]\n",
        "\n",
        "update(p_dist, likelihood);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## Posterior Distribution for p\n",
        "\n",
        ":::{style=\"font-size: .7em\"}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-align: center\n",
        "ax = p_dist.plot(lw=3, legend=False, color='blue', figsize=(10, 4))\n",
        "plt.axvline(0.5, color='red', linestyle='--', lw=2, label='Fair coin (p=0.5)')\n",
        "plt.xlabel('Probability of Heads (p)', size=16)\n",
        "plt.ylabel('Probability', size=16)\n",
        "plt.title('Posterior Distribution of p', size=18)\n",
        "plt.legend(fontsize=14);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The posterior mean is about 0.56, with a 90% credible interval from 0.51 to 0.61.\n",
        "\n",
        "**But this doesn't directly answer:** Is the coin biased or fair?\n",
        "\n",
        ":::\n",
        "\n",
        "## Bayesian Hypothesis Testing\n",
        "\n",
        ":::{style=\"font-size: .8em\"}\n",
        "\n",
        "Instead of estimating $p$, we can compare two **hypotheses**:\n",
        "\n",
        "- **$H_{\\text{fair}}$:** The coin is fair ($p = 0.5$)\n",
        "- **$H_{\\text{biased}}$:** The coin is biased toward heads ($p$ uniformly distributed between 0.6 and 1.0)\n",
        "\n",
        "Since we observed more heads (140) than tails (110), if the coin is biased, it's likely biased toward heads."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "# Create \"biased toward heads\" distribution\n",
        "biased_heads = pd.DataFrame(index=np.arange(101)/100)\n",
        "biased_heads['probs'] = 0\n",
        "# Uniform distribution from 0.6 to 1.0\n",
        "biased_heads.loc[0.6:1.0, 'probs'] = 1\n",
        "biased_heads['probs'] = biased_heads['probs'] / biased_heads['probs'].sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## Visualizing the Hypotheses\n",
        "\n",
        ":::{style=\"font-size: .8em\"}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-align: center\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "# Fair hypothesis\n",
        "ax1.bar([0.5], [1.0], width=0.01, color='red', alpha=0.7)\n",
        "ax1.set_xlabel('Probability of Heads (p)', size=14)\n",
        "ax1.set_ylabel('Probability', size=14)\n",
        "ax1.set_title('Fair Hypothesis: p = 0.5', size=16)\n",
        "ax1.set_xlim(0, 1)\n",
        "\n",
        "# Biased hypothesis\n",
        "biased_heads.plot(ax=ax2, lw=3, legend=False, color='blue')\n",
        "ax2.set_xlabel('Probability of Heads (p)', size=14)\n",
        "ax2.set_ylabel('Probability', size=14)\n",
        "ax2.set_title('Biased Hypothesis: p ~ Uniform(0.6, 1.0)', size=16);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## Computing Likelihoods\n",
        "\n",
        ":::{style=\"font-size: .8em\"}\n",
        "\n",
        "**Likelihood under $H_{\\text{fair}}$:** \n",
        "\n",
        "Probability of 140 heads in 250 flips with $p = 0.5$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "likelihood_fair = binom.pmf(140, 250, p=0.5)\n",
        "print(f\"P(Data | Fair) = {likelihood_fair:.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Likelihood under $H_{\\text{biased}}$:** \n",
        "\n",
        "Average over all possible biased values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "likelihood_vector = [binom.pmf(140, 250, p) for p in biased_heads.index]\n",
        "likelihood_biased = np.sum(biased_heads['probs'] * likelihood_vector)\n",
        "print(f\"P(Data | Biased toward heads) = {likelihood_biased:.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## Bayes Factors\n",
        "\n",
        ":::{style=\"font-size: .8em\"}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from IPython.core.display import HTML\n",
        "\n",
        "def generate_html():\n",
        "    return r\"\"\"\n",
        "    <div class=\"purple-box\">\n",
        "     <span class=\"label\">Bayes Factor</span>\n",
        "        <p>\n",
        "        The Bayes factor \\(K\\) is the ratio of likelihoods under two hypotheses:\n",
        "        $$K = \\frac{P(\\text{Data} | H_A)}{P(\\text{Data} | H_B)}$$\n",
        "\n",
        "        It measures the strength of evidence in favor of hypothesis A over B.\n",
        "        </p>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "html_content = generate_html()\n",
        "display(HTML(html_content))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In our case:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "K = likelihood_fair / likelihood_biased\n",
        "print(f\"Bayes Factor (Fair/Biased) = {K:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Interpretation:** The Bayes factor will tell us which hypothesis the data supports more strongly.\n",
        "\n",
        ":::\n",
        "\n",
        "## Interpreting Bayes Factors\n",
        "\n",
        ":::{style=\"font-size: .8em\"}\n",
        "\n",
        "If we start with equal prior probabilities (50% fair, 50% biased), we can convert the Bayes factor to a posterior probability:\n",
        "\n",
        "$$P(\\text{fair} | \\text{data}) = \\frac{K \\cdot P(\\text{fair})}{K \\cdot P(\\text{fair}) + P(\\text{biased})}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "prior_fair = 0.5\n",
        "posterior_fair = (K * prior_fair) / (K * prior_fair + (1 - prior_fair))\n",
        "print(f\"P(Fair | Data) = {posterior_fair:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data moved us from 50% confidence to 68% confidence that the coin is fair.\n",
        "\n",
        "**Conclusion:** The evidence is weak - not very convincing that the coin is biased.\n",
        "\n",
        ":::\n",
        "\n",
        "## Beyond Hypothesis Testing\n",
        "\n",
        ":::{style=\"font-size: .8em\"}\n",
        "\n",
        "Is it really useful to make a binary decision about whether a coin is biased?\n",
        "\n",
        "More useful questions might be:\n",
        "\n",
        "1. **Prediction:** Based on what we know, what should we expect in the future?\n",
        "\n",
        "2. **Decision-making:** How can we use predictions to make better decisions?\n",
        "\n",
        "We already saw prediction with the World Cup problem (posterior predictive distributions).\n",
        "\n",
        "Next: An example of decision-making with **Bayesian Bandits**.\n",
        "\n",
        ":::\n",
        "\n",
        "##  <span style=\"font-size: 0.9em\">Multi-Armed Bandit Problem</span>\n",
        "\n",
        ":::{style=\"font-size: .7em\"}\n",
        "\n",
        "A slot machine is sometimes called a \"one-armed bandit.\"\n",
        "\n",
        ":::{.center-text}\n",
        "<img src=\"images/bayesian_testing/slot_machines.jpeg\" width=400/>\n",
        ":::\n",
        "\n",
        "**Scenario:** You have 4 slot machines. Each has a different (unknown) probability of winning. How do you maximize your winnings?\n",
        "\n",
        "- Play all equally until you find the best? (Too much exploration)\n",
        "- Pick the current best and play it exclusively? (Too much exploitation)\n",
        "\n",
        "**Solution:** Balance exploration and exploitation!\n",
        "\n",
        ":::\n",
        "\n",
        "## Setting Up the Bandits\n",
        "\n",
        ":::{style=\"font-size: .8em\"}\n",
        "\n",
        "We start with uniform priors for each machine (we know nothing about win probabilities):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "p_prior = pd.DataFrame(index=np.arange(101)/100)\n",
        "p_prior['probs'] = 1/101\n",
        "beliefs = [p_prior.copy() for i in range(4)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-align: center\n",
        "fig, axes = plt.subplots(1, 4, figsize=(14, 3))\n",
        "for i, pmf in enumerate(beliefs):\n",
        "    pmf.plot(ax=axes[i], lw=3, legend=False, color='blue')\n",
        "    axes[i].set_title(f'Machine {i}', size=12)\n",
        "    axes[i].set_xlabel('Win Probability (p)', size=10)\n",
        "    axes[i].set_ylabel('Probability', size=10)\n",
        "plt.tight_layout();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## Updating Beliefs\n",
        "\n",
        ":::{style=\"font-size: .8em\"}\n",
        "\n",
        "After playing a machine, we update our beliefs based on the outcome:\n",
        "\n",
        "- **Win:** Multiply by $p$ (higher $p$ values become more likely)\n",
        "- **Loss:** Multiply by $(1-p)$ (lower $p$ values become more likely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "def update_bandit(belief, outcome):\n",
        "    '''Update belief about a machine based on win/loss outcome'''\n",
        "    if outcome == 'W':\n",
        "        update(belief, belief.index)\n",
        "    elif outcome == 'L':\n",
        "        update(belief, 1 - belief.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## Example: One Machine, 10 Plays\n",
        "\n",
        ":::{style=\"font-size: .8em\"}\n",
        "\n",
        "Suppose we play one machine 10 times with outcomes: W, L, L, L, L, L, L, L, L, L"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-align: center\n",
        "bandit = p_prior.copy()\n",
        "for outcome in 'WLLLLLLLLL':\n",
        "    update_bandit(bandit, outcome)\n",
        "\n",
        "bandit.plot(lw=3, legend=False, color='blue', figsize=(10, 4))\n",
        "plt.xlabel('Win Probability (p)', size=16)\n",
        "plt.ylabel('Probability', size=16)\n",
        "plt.title('Posterior After 1 Win, 9 Losses', size=18);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The posterior shifts toward low win probabilities - this looks like a bad machine!\n",
        "\n",
        ":::\n",
        "\n",
        "## Let's Play! (Interactive Demo)\n",
        "\n",
        ":::{style=\"font-size: .7em\"}\n",
        "\n",
        "**For live interaction:** This section works best if you can run Python code live during the presentation. Options:\n",
        "\n",
        "1. **Jupyter Notebook:** Render the .qmd to .ipynb and present from Jupyter\n",
        "2. **VS Code:** Use Quarto preview with a Python kernel\n",
        "3. **Google Colab:** Upload the notebook and run interactively\n",
        "\n",
        "Now let's set up 4 machines and play interactively. **You tell me which machine to play!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "# Reset: 4 machines with uniform priors\n",
        "beliefs = [p_prior.copy() for i in range(4)]\n",
        "play_history = []\n",
        "\n",
        "# True probabilities (unknown to us!)\n",
        "actual_probs = [0.10, 0.20, 0.30, 0.40]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "def show_beliefs():\n",
        "    '''Display current beliefs for all 4 machines'''\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(14, 3))\n",
        "    for i, pmf in enumerate(beliefs):\n",
        "        pmf.plot(ax=axes[i], lw=3, legend=False, color='blue')\n",
        "        mean_p = np.sum(pmf.index * pmf['probs'])\n",
        "        axes[i].set_title(f'Machine {i} (mean={mean_p:.2f})', size=12)\n",
        "        axes[i].set_xlabel('p', size=10)\n",
        "        axes[i].set_ylabel('Probability', size=10)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def play_machine(machine_num):\n",
        "    '''Play a specific machine and update beliefs'''\n",
        "    # Play the machine\n",
        "    p = actual_probs[machine_num]\n",
        "    outcome = 'W' if np.random.random() < p else 'L'\n",
        "\n",
        "    # Update belief\n",
        "    update_bandit(beliefs[machine_num], outcome)\n",
        "\n",
        "    # Record history\n",
        "    play_history.append((machine_num, outcome))\n",
        "\n",
        "    # Show result\n",
        "    print(f\"\\nðŸŽ° Played Machine {machine_num}: {outcome}!\")\n",
        "    print(f\"   History: {len([h for h in play_history if h[0]==machine_num])} plays, \" +\n",
        "          f\"{len([h for h in play_history if h[0]==machine_num and h[1]=='W'])} wins\")\n",
        "\n",
        "    # Show updated beliefs\n",
        "    show_beliefs()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use: `play_machine(0)`, `play_machine(1)`, `play_machine(2)`, or `play_machine(3)`\n",
        "\n",
        ":::\n",
        "\n",
        "## Current State\n",
        "\n",
        ":::{style=\"font-size: .8em\"}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-align: center\n",
        "show_beliefs()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Which machine should we play first? Call out a number 0-3!**\n",
        "\n",
        "_(In class: Run `play_machine(X)` based on student suggestions 5-10 times)_\n",
        "\n",
        ":::\n",
        "\n",
        "## What Strategy Did We Use?\n",
        "\n",
        ":::{style=\"font-size: .8em\"}\n",
        "\n",
        "After playing manually, we probably:\n",
        "- Explored all machines early on\n",
        "- Started favoring machines that seemed better\n",
        "- Occasionally checked \"worse\" machines to see if we were wrong\n",
        "\n",
        "**Question:** Is there an optimal strategy that automatically balances exploration and exploitation?\n",
        "\n",
        "**Answer:** Yes! **Thompson Sampling**\n",
        "\n",
        ":::\n",
        "\n",
        "## Thompson Sampling Strategy\n",
        "\n",
        ":::{style=\"font-size: .8em\"}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from IPython.core.display import HTML\n",
        "\n",
        "def generate_html():\n",
        "    return r\"\"\"\n",
        "    <div class=\"purple-box\">\n",
        "     <span class=\"label\">Thompson Sampling</span>\n",
        "        <p>\n",
        "        To choose which machine to play next:\n",
        "        <br>\n",
        "        1. Draw one random sample from each machine's posterior distribution<br>\n",
        "        2. Play the machine with the highest sampled value\n",
        "        <br><br>\n",
        "        This automatically balances exploration and exploitation!\n",
        "        </p>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "html_content = generate_html()\n",
        "display(HTML(html_content))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Machines with higher expected win rates get sampled more often, but uncertainty (wide distributions) gives other machines a chance.\n",
        "\n",
        ":::\n",
        "\n",
        "## Implementing Thompson Sampling\n",
        "\n",
        ":::{style=\"font-size: .8em\"}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "def choose(beliefs):\n",
        "    '''Use Thompson sampling to choose a machine'''\n",
        "    ps = [np.random.choice(b.index, p=b['probs']) for b in beliefs]\n",
        "    return np.argmax(ps)\n",
        "\n",
        "# Simulate playing a machine\n",
        "actual_probs = [0.10, 0.20, 0.30, 0.40]  # Unknown to us!\n",
        "counter = Counter()\n",
        "\n",
        "def play(i):\n",
        "    '''Play machine i and return outcome'''\n",
        "    counter[i] += 1\n",
        "    p = actual_probs[i]\n",
        "    if np.random.random() < p:\n",
        "        return 'W'\n",
        "    else:\n",
        "        return 'L'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## Running the Strategy\n",
        "\n",
        ":::{style=\"font-size: .7em\"}\n",
        "\n",
        "Let's play 100 times using Thompson sampling:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "# Reset beliefs and counter\n",
        "beliefs = [p_prior.copy() for i in range(4)]\n",
        "counter = Counter()\n",
        "num_plays = 100\n",
        "\n",
        "for _ in range(num_plays):\n",
        "    machine = choose(beliefs)\n",
        "    outcome = play(machine)\n",
        "    update_bandit(beliefs[machine], outcome)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-align: center\n",
        "fig, axes = plt.subplots(1, 4, figsize=(14, 3))\n",
        "for i, pmf in enumerate(beliefs):\n",
        "    pmf.plot(ax=axes[i], lw=3, legend=False, color='blue')\n",
        "    axes[i].set_title(f'Machine {i} (True p={actual_probs[i]:.1f})', size=12)\n",
        "    axes[i].set_xlabel('Win Probability (p)', size=10)\n",
        "    axes[i].set_ylabel('Probability', size=10)\n",
        "plt.tight_layout();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## <span style=\"font-size: 0.8em\">How Often Did We Play Each Machine?</span>\n",
        "\n",
        ":::{style=\"font-size: .8em\"}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "index = range(4)\n",
        "columns = ['Actual P(win)', 'Times played']\n",
        "df = pd.DataFrame(index=index, columns=columns)\n",
        "for i in range(4):\n",
        "    df.loc[i] = [actual_probs[i], counter.get(i, 0)]\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key observation:** We played the better machines more often!\n",
        "\n",
        "- Early on: Explore all machines to learn about them\n",
        "- Later: Exploit the best machines while still occasionally checking others\n",
        "\n",
        "This is the power of Thompson sampling: it balances exploration and exploitation automatically.\n",
        "\n",
        ":::\n",
        "\n",
        "## Summary\n",
        "\n",
        ":::{style=\"font-size: .8em\"}\n",
        "\n",
        "**Key Concepts:**\n",
        "\n",
        "1. **Bayes factors** compare the evidence for two hypotheses by taking the ratio of likelihoods\n",
        "\n",
        "2. **Bayesian hypothesis testing** provides an alternative to p-values, but depends on how you define hypotheses\n",
        "\n",
        "3. **Thompson sampling** uses posterior distributions to make optimal decisions that balance exploration and exploitation\n",
        "\n",
        "4. **Decision-making** often matters more than hypothesis testing - use predictions to guide actions!\n",
        "\n",
        ":::\n",
        "\n",
        "## Group Question\n",
        "\n",
        ":::{style=\"font-size: .65em\"}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from IPython.core.display import HTML\n",
        "\n",
        "def generate_html():\n",
        "    return r\"\"\"\n",
        "    <div class=\"blue-box\">\n",
        "        <p>\n",
        "<b>Casino Coin Problem:</b> You're at a casino and suspect a coin might be biased. You flip it 20 times and observe 14 heads and 6 tails.\n",
        "<br><br>\n",
        "Define two hypotheses:\n",
        "<br>\n",
        "â€¢ <b>Fair:</b> p = 0.5<br>\n",
        "â€¢ <b>Biased toward heads:</b> p is uniformly distributed between 0.5 and 1.0<br>\n",
        "<br>\n",
        "<b>a.</b> Compute P(Data | Fair).\n",
        "<br><br><br>\n",
        "        </p>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "html_content = generate_html()\n",
        "display(HTML(html_content))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## Group Question (cont'd)\n",
        "\n",
        ":::{style=\"font-size: .65em\"}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from IPython.core.display import HTML\n",
        "\n",
        "def generate_html():\n",
        "    return r\"\"\"\n",
        "    <div class=\"blue-box\">\n",
        "        <p>\n",
        "<b>b.</b> To compute P(Data | Biased toward heads), you need to average over all possible values of p between 0.5 and 1.0. Explain in words how you would compute this. (You don't need to write code, just describe the process.)\n",
        "<br><br><br><br>\n",
        "<b>c.</b> If the Bayes factor (Fair/Biased) turns out to be 0.5, and you started with equal priors (50% chance of each hypothesis), what is your posterior probability that the coin is fair?\n",
        "<br><br><br><br>\n",
        "        </p>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "html_content = generate_html()\n",
        "display(HTML(html_content))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/laurenwheelock/Library/Python/3.9/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}