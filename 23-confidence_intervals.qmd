---
title: Confidence Intervals 
author: "CDS DS-122<br>Boston University"
format: 
    revealjs:
        math: true
        css: 
        - styles.css
        html-math-method: mathjax
        highlight-style: github
        slide-number: true
        show-slide-number: all
        chalkboard: true 
---

## Life Better With a TV?
:::{style="font-size: .8em"}
A survey studied the relationship between TV ownership and well-being. 

:::{.center-text}
<img src="images/ci/couch_potato.png" width=300/>
::: 

Participants were presented with a ladder where steps numbered 0 to 10:

- 0 is the worst possible life
- 10 is the best possible life

They were asked which step came closest to the way they felt about their life.


:::

## Life Better With a TV?
:::{style="font-size: .8em"}

:::{.center-text}
<img src="images/ci/Gallup_survey.png" width=700/>
:::

_"For the European data, one can say with 95% confidence that the true population for wellbeing among those without TVs is between 4.88 and <br> 5.26 [...]"_

The confidence interval: _between 4.88 and 5.26._

**The survey does not tell us that watching TV is good for our well-being,  just that owning one is!**


:::


## Learning Objectives
:::{style="font-size: .8em"}

- Definition of confidence intervals
- Confidence intervals for the mean of the normal distribution
    * with a known variance
    * with an unknown variance
- The $t$ distribution
- Confidence intervals for the mean of any distribution
- Visualizing and reporting confidence intervals

:::

## Study Hours
:::{style="font-size: .8em"}
A random sample of 50 students was selected as part of a study on weekly study hours. The average study hours
were found to be 15 hours. In a very large study in the fall semester of the previous year, it was found
that the standard deviation of the study hours was 4 hours. This standard deviation can be assumed to
be the population standard deviation.

:::{.center-text}
<img src="images/ci/Study_hours.jpeg" width=300/>
:::


__Question__: Provide the 95% confidence interval for the mean study hours in the new study.
:::

## Confidence Intervals
:::{style="font-size: .8em"}
 Confidence intervals provide an alternative to using a point estimator $\hat{\theta}$ when we wish to estimate an unknown population parameter $\theta$. 


```{python}
from IPython.core.display import HTML

def generate_html():
    return r"""
    <div class="purple-box">
     <span class="label"> Confidence Interval </span>
        <p>
        
    A confidence interval is a random interval, calculated from the sample, that contains \(\theta\) with some specified probability.
        </p>
    </div>
    """
html_content = generate_html()
display(HTML(html_content))
``` 

That is, a 95% confidence interval for $\theta$ is a random interval that contains $\theta$ with probability 0.95.

__Example__: Assume that a populaiton is normally distributed with mean $\mu$ and variance $\sigma^2$. For instance, we can think of SAT scores for students in Massachusetts.

To estimate the true value of $\mu$ we repeat the sampling process 20 times and compute the confidence interval for parameter $\mu$ for each sample. 
:::

## Confidence Intervals
:::{style="font-size: .8em"}
__Example (continued)__: 
```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import norm
from scipy.stats import uniform
from numpy.random import default_rng
import scipy.stats as stats

rng = default_rng(13)

# Data from 2020 for SAT scores nationwide from above link
mu = 1050
sig = 216
#
# gaussian curve
fig, (ax1, ax2) = plt.subplots(2, 1, figsize = (10,5), gridspec_kw={'height_ratios': [2, 7]})
x = np.linspace(norm.ppf(0.001, loc = mu, scale = sig), norm.ppf(0.999, loc = mu, scale = sig), 100)
xmin, xmax = (x[0], x[-1])
ax1.plot(x, norm.pdf(x, loc = mu, scale = sig),'k-', lw = 5, alpha = 0.6)
#
# points under the curve
pop_x = norm.rvs(size = 1000, loc = mu, scale = sig)
pop_y = [uniform.rvs(size = 1, scale = norm.pdf(x_coord, loc = mu, scale = sig)) for x_coord in pop_x]
ax1.scatter(pop_x, pop_y, marker = '.', alpha = 0.5, color = 'darkblue')
ax1.yaxis.set_major_locator(plt.NullLocator())
ax1.set_ylabel('Density', size = 16)
ax1.text(1400, np.sum(ax1.get_ylim())/2, 'Population', size = 16, color = 'darkblue')
ax1.set_xlim(xmin, xmax)
# xmin, xmax = ax1.get_xlim()
#
# samples
#
def contains(mu, M, f):
    return (M < (mu + f) and M > (mu - f))

samp_size = 15
t_stat = stats.t.ppf(1-0.025, samp_size - 1)
for samp in range (20):
    samp_x = norm.rvs(size = samp_size, loc = mu, scale = sig, random_state = rng)
    M = np.mean(samp_x)
    std_err = np.std(samp_x) / np.sqrt(samp_size)
    if contains(mu, M, t_stat * std_err):
        col = 'g'
    else:
        col = 'orange'
    #
    ax2.scatter(M, samp, marker = 'o', facecolors = col, edgecolors=col, linewidths = 1.5, s = 64)
    ax2.errorbar(M, samp, xerr = t_stat * std_err, fmt = 'None', ecolor = col, elinewidth = 1.5, capsize = 10, capthick = 1.5)
#
ax2.set_xlim(xmin, xmax)
ax2.set_ylim(-1, 22)
#
ax2.vlines(mu, -1, 20, colors = 'darkblue')
ax2.text(mu, 21, r'$\mu$', size = 20, color = 'darkblue', ha = 'center', va = 'center')
#ax2.text(M+f, 1.75, r'$M + f$', size = 20, color = 'g', ha = 'left', va = 'center')
#ax2.text(M-f, 1.75, r'$M - f$', size = 20, color = 'g', ha = 'right', va = 'center');
ax2.yaxis.set_visible(False)
ax2.xaxis.set_visible(False)
for spine in ax2.spines.values():
    spine.set_visible(False)
#
#ax1.set_title('SAT Scores', size=18)
plt.tight_layout(h_pad = -2);
```
:::

## Confidence Intervals
:::{style="font-size: .8em"}
__Example (continued)__: 

Note: 

- The confidence intervals dance around and their sizes vary.
- The orange intervals do not contain the population mean $\mu.$
- Roughly 95% of the confidence intervals do contain the true mean.

Now that we understand how to interpret confidence intervals, the next question is how to compute them.
:::

## Mean of a Normal Distribution
:::{style="font-size: .8em"}
_**Assume that our population has a Gaussian (i.e., normal) distribution.**_

Let $x^{(1)}, x^{(2)},, ..., x^{(n)}$ be a random sample from a population that has a _**normal distribution with unknown mean**_ $\mu$ _**and known variance**_ $\sigma^2$. <br>
Denote the _**sample mean**_ as

$$M = \overline{X} = \frac{1}{n} \sum_{i=1}^n x^{(i)}.$$ 

Let $z(\alpha)$ be the number for which the area under the standard normal density function to the right of $z(\alpha)$ is $\alpha$ with $0 \leq \alpha \leq 1$. Note that the symmetry of the standard normal density function about zero implies that $z(1-\alpha) = -z(\alpha)$.
:::

## Mean of a Normal Distribution
:::{style="font-size: .8em"}
:::{.center-text}
<img src="images/ci/Standard_normal_density_z.png" width=550/>
:::
:::

## Mean of a Normal Distribution
:::{style="font-size: .8em"}
If random variable $Z$ follows the standard normal distribution, then, by definition of $z(\alpha)$,

$$\small{P\left(-z(\alpha/2) \leq Z \leq z(\alpha/2)\right) = 1-\alpha.}$$

$\frac{M - \mu}{\sigma/\sqrt{n}}$ has the standard normal distribution, so

$$\small{P\left(-z(\alpha/2) \leq \frac{M - \mu}{\sigma/\sqrt{n}} \leq z(\alpha/2)\right) = 1-\alpha.}$$

Elementary manipulation of the inequalities gives 

$$\small{P\left(M - z(\alpha/2) \frac{\sigma}{\sqrt{n}} \leq \mu \leq M + z(\alpha/2)  \frac{\sigma}{\sqrt{n}} \right) = 1-\alpha.}$$
:::

## Mean of a Normal Distribution
:::{style="font-size: .8em"}
This implies that the probability that $\mu$ lies in the interval 

$$\left[M - z(\alpha/2)  \frac{\sigma}{\sqrt{n}}, M + z(\alpha/2)  \frac{\sigma}{\sqrt{n}}\right]$$

is approximately $1-\alpha.$ In other words, this is a _**$100(1-\alpha)\%$ confidence interval**_ for the population mean, $\mu$.

<br><br>

What happens when the population variance, $\sigma^2$, is _**not known**_?

How can we replace it?
:::

## Unknown Population Variance
:::{style="font-size: .8em"}
Of course, we can estimate $\sigma$ from the data. 
 
$\sqrt{\frac{1}{n}\sum_i (x_i - M)^2}$ is a __biased__ estimate of the true standard deviation, so we typically apply _**Bessel's correction**_ to get an __unbiased__ estimate:

$$ s = \sqrt{\frac{1}{n-1}\sum_i (x_i - M)^2}. $$

This substitution has a far-reaching consequence: _**the distribution of $\frac{M - \mu}{s/\sqrt{n}}$ is a <br>
$t$ distribution with $n-1$ degrees of freedom.**_
:::

## The $t$ Distribution
:::{style="font-size: .8em"}

 A man named William Gosset worked at the Guinness Brewery in Ireland. He needed a way to determine if changes in the brewing processes made a difference. Unfortunately, he generally only had small samples sizes.

:::{.center-text}
<img src="images/ci/Guiness.jpg" width=550/>
:::

:::

## The $t$ Distribution
:::{style="font-size: .8em"}
William Gosset introduced the $t$-distribution after realizing the normal distribution wasn't suitable for small samples. Its heavier tails reflect a higher chance of extreme values, especially with smaller sample sizes. <br>
<br>
As $\nu$ (the degres of freedom, $\nu=n-1$) goes to infinity, we get the normal distribution.

:::{.center-text}
<img src="images/ci/Student_t.png" width=350/>
:::

:::

<!-- ## The $t$ Distribution
:::{style="font-size: .78em"}
We assume again that $x^{(1)}, x^{(2)},, ..., x^{(n)}$ be a random sample from a normal distribution having mean $\mu$ and variance $\sigma^2$. Let $\tau_{n-1}(x)$ denote the PDF of the $t$ distribution with $n-1$ degrees of freedom and $t$ be a constant such that 

$$\small{\int_{-t}^t \tau_{n-1}(x) dx = 1 - \alpha.}$$

For every value of $n$, the value of $t$ can be found from the table of the $t$ distribution. For example, if $n = 12$ and $T_{11}(x)$ denotes the CDF of the $t$ distribution with 11 degrees of freedom, then

$$\small{\int_{-t}^t \tau_{11}(x) dx = T_{11}(t) - T_{11}(-t) = T_{11}(t) - (1-T_{11}(t)) = 2T_{11}(t) - 1.}$$

If $\alpha = 0.05$, it follows that $T_{11}(t) = 0.975$. It is found from the table that $t = 2.201$, the 0.975 quantile of the $t$ distribution with 11 degrees of freedom.  
::: -->

## The $t$ Distribution
:::{style="font-size: .8em"}
When the population standard deviation $\sigma$ is not known the $100(1-\alpha)\%$ confidence interval becomes 

$$\left[M - t_{n-1}(\alpha/2)  \frac{s}{\sqrt{n}}, M + t_{n-1}(\alpha/2)  \frac{s}{\sqrt{n}}\right].$$ 

Since people often prefer to use the normal distribution, and since the $t$-distribution becomes equivalent to the normal when the sample size $n$ becomes large, common practice is to use normal distribution instead of the $t$-distribution for $n \geq 30$. 

_**For this course, we recommend using exclusively $t$-distribution when the population standard deviation is not known.**_
:::

## Mean of Any Distribution
:::{style="font-size: .8em"}
What happens if the type of the population distribution is not known?

Let $x^{(1)}, x^{(2)},, ..., x^{(n)}$ be a random sample from a population that has an __unknown distribution__ with __unknown mean__ $\mu$ and __known variance__ $\sigma^2$. Let 

$$M = \overline{X} = \frac{1}{n} \sum_{i=1}^n x_i.$$ 

The Central Limit Theorem tells us that the distribution of $\frac{M - \mu}{\sigma/\sqrt{n}}$ can be approximated by a standard normal distribution, so

$$P\left(-z(\alpha/2) \leq \frac{M - \mu}{\sigma/\sqrt{n}} \leq z(\alpha/2)\right) = 1-\alpha.$$
:::

## Mean of Any Distribution
:::{style="font-size: .8em"}
This is the same expression as we found before. Thus, the $100(1-\alpha)\%$ confidence interval is simply 

$$\left[M - z(\alpha/2)  \frac{\sigma}{\sqrt{n}}, M + z(\alpha/2)  \frac{\sigma}{\sqrt{n}}\right].$$

When the sample of size $n$ is from a population that has an __unknown distribution__ with __unknown mean__ $\mu$ and __unknown variance__ $\sigma^2$, the $100(1-\alpha)\%$ confidence interval becomes 

$$\left[M - t_{n-1}(\alpha/2)  \frac{s}{\sqrt{n}}, M + t_{n-1}(\alpha/2)  \frac{s}{\sqrt{n}}\right].$$ 


Here, $s$ is again an unbiased estimate of the true standard deviation.
:::

## Mean of Any Distribution
:::{style="font-size: .8em"}
How large should $n$ be for us to be able to rely on the central limit theorem?
<br><br>

The answer is that it depends on the population distribution. A highly skewed distribution, or one with a large ratio of standard deviation to mean, will require larger sample sizes.
:::

## Visualizing CIs
:::{style="font-size: .8em"}
For the SAT example, the figure below shows the 95% confidence intervals for the population mean based on a sample of size 15 and a sample of size 50.

```{python}
rng = default_rng(12)

# Data from 2020 for SAT scores nationwide from above link
mu = 1050
sig = 216
#
# gaussian curve
fig, (ax1, ax1a, ax2) = plt.subplots(3, 1, figsize = (14,5), gridspec_kw={'height_ratios': [8, 1, 8]})
x = np.linspace(norm.ppf(0.001, loc = mu, scale = sig), norm.ppf(0.999, loc = mu, scale = sig), 100)
xmin, xmax = (x[0], x[-1])
ax1.plot(x, norm.pdf(x, loc = mu, scale = sig),'k-', lw = 5, alpha = 0.6)
#
# points under the curve
pop_x = norm.rvs(size = 1000, loc = mu, scale = sig)
pop_y = [uniform.rvs(size = 1, scale = norm.pdf(x_coord, loc = mu, scale = sig)) for x_coord in pop_x]
ax1.scatter(pop_x, pop_y, marker = '.', alpha = 0.5, color = 'darkblue')
ax1.yaxis.set_major_locator(plt.NullLocator())
ax1.set_ylabel('Density', size = 16)
ax1.text(1400, np.sum(ax1.get_ylim())/2, 'Population', size = 16, color = 'darkblue')
ax1.set_xlim(xmin, xmax)
# xmin, xmax = ax1.get_xlim()
#
# sample
#
samp_size = 15
t_stat = stats.t.ppf(1-0.025, samp_size - 1)
samp_x = norm.rvs(size = samp_size, loc = mu, scale = sig, random_state = rng)
samp_y = [2.75 for x in samp_x]
M = np.mean(samp_x)
std_err = np.std(samp_x) / np.sqrt(samp_size)
#
ax2.set_xlim(xmin, xmax)
ax2.set_ylim(0.5, 3)
#
ax2.scatter(samp_x, samp_y, marker = 'o', facecolors='none', edgecolors='red', linewidths = 1.5, s = 48)
ax2.text(xmax, 2.75, 'Sample $n = 15$', size = 16, color = 'red', va = 'center', ha = 'right')
ax2.scatter(M, 2.25, marker = 'o', facecolors = 'g', edgecolors='g', linewidths = 1.5, s = 64)
ax2.errorbar(M, 2.25, xerr = t_stat * std_err, fmt = 'None', ecolor = 'g', elinewidth = 1.5, capsize = 10, capthick = 1.5)
ax2.text(xmax, 2.25, 'Confidence Interval for $\mu$', size = 16, color = 'g', va = 'center', ha = 'right')
ax2.text(M, 2, 'M', size = 20, color = 'g', ha = 'center', va = 'center')
#
samp_size = 50
samp_x = norm.rvs(size = samp_size, loc = mu, scale = sig, random_state = rng)
samp_y = [1.25 for x in samp_x]
M = np.mean(samp_x)
std_err = np.std(samp_x) / np.sqrt(samp_size)
#
ax2.scatter(samp_x, samp_y, marker = 'o', facecolors='none', edgecolors='red', linewidths = 1.5, s = 48)
ax2.text(xmax, 1.25, 'Sample $n = 50$', size = 16, color = 'red', va = 'center', ha = 'right')
ax2.scatter(M, 0.75, marker = 'o', facecolors = 'g', edgecolors='g', linewidths = 1.5, s = 64)
ax2.errorbar(M, 0.75, xerr = 1.96 * std_err, fmt = 'None', ecolor = 'g', elinewidth = 1.5, capsize = 10, capthick = 1.5)
ax2.text(xmax, 0.75, 'Confidence Interval for $\mu$', size = 16, color = 'g', va = 'center', ha = 'right')
ax2.text(M, 0.5, 'M', size = 20, color = 'g', ha = 'center', va = 'center')

#ax2.text(M+f, 1.75, r'$M + f$', size = 20, color = 'g', ha = 'left', va = 'center')
#ax2.text(M-f, 1.75, r'$M - f$', size = 20, color = 'g', ha = 'right', va = 'center');
ax2.yaxis.set_visible(False)
ax2.xaxis.set_visible(False)
for spine in ax2.spines.values():
    spine.set_visible(False)
#
ax1a.text(mu, np.sum(ax1a.get_ylim())/2, '$\mu$', size = 20, color = 'darkblue', ha = 'center')
# ax1a.text(mu+sig, np.sum(ax1a.get_ylim())/2, '$\mu+\sigma$', size = 20, color = 'darkblue', ha = 'left')
ax1a.text(mu, ax1a.get_ylim()[1], '^', size = 20, color = 'darkblue', ha = 'center')
# ax1a.text(mu+sig, ax1a.get_ylim()[1], '^', size = 20, color = 'darkblue', ha = 'left')
ax1a.yaxis.set_visible(False)
ax1a.xaxis.set_visible(False)
for spine in ax1a.spines.values():
    spine.set_visible(False)
ax1a.set_xlim(xmin, xmax)
#
ax1.set_title('SAT Scores', size=18);
```

:::

<!-- ## Reporting CIs
:::{style="font-size: .8em"}
What is the role of confidence intervals in summarizing data?

The simple answer is __confidence intervals are crucial.__

You cannot communicate with clarity without reporting confidence intervals.

__Any time__ you are reporting a statistic derived from a sample, such as the sample mean, you should report the associated confidence intervals.

Confidence intervals combine information on location and precision.  

They tell you (or your reader) both __how large__ is the quantity (location) and __how much information__ the estimate provides.

::: -->

## Reporting CIs
:::{style="font-size: .8em"}
There are standard ways for reporting confidence intervals.

In text, we write:

$M = 30.5 \text{cm, 95% CI } [18.0, 43.0]$

In a table, we can use this format:

|   | height | 95% CI |
|---|---|---|
| men, n = 25 | 69.0 in | [68.1, 69.9]|
| women, n = 23 | 61.1 in | [60.2, 62.0] |

:::

## Reporting CIs
:::{style="font-size: .8em"}
In this lecture we've computed 95% confidence intervals.   Some statisticians will suggest that you may want to use a different confidence level depending on the setting.

If your results will be used to make life-or-death decisions, perhaps a 99% or even a 99.9% confidence interval should be used.  

On the other hand, if we are not so concerned about an occasional miss, perhaps a 90% or 80% confidence interval should be used. 

These are reasonable considerations, but in general work it's probably best to stick with 95% confidence intervals for consistency and ease of interpretation.
:::

## Study Hours
:::{style="font-size: .8em"}
A random sample of 50 students was selected as part of a study on weekly study hours. The average study hours
were found to be 15 hours. In a very large study in the fall semester of the previous year, it was found
that the standard deviation of the study hours was 4 hours. This standard deviation can be assumed to
be the population standard deviation.

:::{.center-text}
<img src="images/ci/Study_hours.jpeg" width=300/>
:::


__Question__: Provide the 95% confidence interval for the mean study hours in the new study.
:::

## Study Hours
:::{style="font-size: .8em"}
- Sample size: $n = 50$
- Sample mean: $M = 15$
- Population standard deviation: $\sigma = 4$

The 95% confidence interval is given by 

\begin{align*}
&\left[M - z(\alpha/2)  \frac{\sigma}{\sqrt{n}}, M + z(\alpha/2)  \frac{\sigma}{\sqrt{n}}\right] = \\
& \left[15 - 1.96  \frac{4}{\sqrt{50}}, 15 + 1.96  \frac{4}{\sqrt{50}}\right] = \\
& [13.89, 16.11]
\end{align*}
:::

## Group Question 1
:::{style="font-size: .8em"}
```{python}
from IPython.core.display import HTML

def generate_html():
    return r"""
    <div class="blue-box">
        <p>
   A random sample of 40 households was selected as part of a study on electricity usage, and the number of kilowatt-hours (kWh) was recorded for each household in the sample for the first quarter of 2023. The average usage was found to be 310 kWh. In a very large study in the first quarter of the previous year, it was found that the standard deviation of the usage was 89 kWh.<br>
    a. 
    Assuming the standard deviation is unchanged, provide the 95% confidence interval for the mean usage in the first quarter of 2023.<br>
    <br>
    <br>
    b. Repeat the previous question for a 99% confidence interval.<br>
    <br>
    <br>
    </div>
    """
html_content = generate_html()
display(HTML(html_content))
```
:::

:::{.notes}
a. In this problem the sample size $n$ is equal to 40, the sample mean $\overline{X}$ is equal to 310 kWh, and the population standard deviation $\sigma$ is 89 kWh. Then from the CLT we know that
$$\overline{X} \sim N\left(310, \left( \frac{89}{\sqrt{40}}\right)^2\right).$$ Since the population standard deviation is provided, we can use the $Z$-score of 1.96 for the 95\% confidence interval computation (see the $Z$-table). The desired interval is then given by 
$$\left[\overline{X}-1.96\:\frac{\sigma}{n}, \overline{X}+1.96\:\frac{\sigma}{n}\right] = \left[310 - 1.96 \frac{89}{\sqrt{40}}, 310 + 1.96 \frac{89}{\sqrt{40}}\right]=\left[282.4, 337.6\right].$$
b. For the 99\% confidence interval the $Z$-score is equal to 2.58 (see the $Z$-table). Thus, we obtain
$$\left[\overline{X}-2.58\:\frac{\sigma}{n}, \overline{X}+2.58\:\frac{\sigma}{n}\right] = \left[310 - 2.58 \frac{89}{\sqrt{40}}, 310 + 2.58 \frac{89}{\sqrt{40}}\right]=\left[273.7, 346.3\right].$$
:::