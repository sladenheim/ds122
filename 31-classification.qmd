---
title: Classification & Naive Bayes
author: "CDS DS-122<br>Boston University"
format:
    revealjs:
        math: true
        css:
        - styles.css
        html-math-method: mathjax
        highlight-style: github
        slide-number: true
        show-slide-number: all
        chalkboard: true
---

```{python}
#| echo: false
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import norm, multivariate_normal

def update(distribution, likelihood):
    '''Standard Bayesian update function'''
    distribution['probs'] = distribution['probs'] * likelihood
    prob_data = distribution['probs'].sum()
    distribution['probs'] = distribution['probs'] / prob_data
    return distribution

```

## Learning Objectives
:::{style="font-size: .8em"}

- Explain what a classification problem is and give examples
- Implement a Naive Bayes classifier using Bayesian updating
- Understand the "naive" assumption and why it matters
- Compare naive Bayes to multivariate normal classifiers
- Evaluate classifier performance

:::

# Classification Problems

## What is Classification?

:::{style="font-size: .8em"}

**Classification:** Predicting which category/class an observation belongs to

**Examples:**

- Is this email spam or not spam?
- Is this tumor benign or malignant?
- Will this customer churn or stay?
- Is this transaction fraudulent?


**Classification is one of the most common applications of Bayesian methods!**

:::

## <span style="font-size: 0.7em">Spam Filtering: The Original Application</span>

:::{style="font-size: .8em"}

In the 1990s, Bayesian classification revolutionized spam filtering.


**The idea:**

- Calculate P(spam | words in email)
- Words like "FREE", "WINNER", "VIAGRA" increase probability of spam
- Words like "meeting", "deadline", "attached" decrease it


```{python}
#| echo: false
import pandas as pd
import numpy as np

# Example word probabilities
data = {
    'Word': ['FREE', 'WINNER', 'meeting', 'deadline', 'viagra'],
    'P(word|spam)': [0.65, 0.58, 0.12, 0.08, 0.82],
    'P(word|ham)': [0.03, 0.02, 0.45, 0.38, 0.001]
}
df_spam = pd.DataFrame(data)
print(df_spam.to_string(index=False))
```

. . .

**Result:** Simple Bayesian classifiers achieved 95%+ accuracy!

:::

## Penguin Classification

:::{style="font-size: .8em"}

We'll work with something cuter - classifying penguins into three species using physical measurements.

::: {.columns}
::: {.column width="33%"}
![**Adélie Penguin** - Smallest, classic "tuxedo" look](images/classification/adelie.jpg){width=200}
:::
::: {.column width="33%"}
![**Chinstrap Penguin** - Named for black facial stripe](images/classification/chinstrap.jpg){width=200}
:::
::: {.column width="33%"}
![**Gentoo Penguin** - Largest, orange beak](images/classification/gentoo.png){width=200}
:::
:::

:::

## The Palmer Penguins Dataset

Data on 344 penguins found on the Palmer Archipelago in the Antartic, including flipper and culmen (beak) length:

:::{style="font-size: .8em"}

```{python}
# Load the Palmer Penguins dataset
# You can install with: pip install palmerpenguins
try:
    from palmerpenguins import load_penguins
    df = load_penguins()
    # Rename columns to match our convention
    df = df.rename(columns={
        'flipper_length_mm': 'Flipper Length (mm)',
        'bill_length_mm': 'Culmen Length (mm)',
        'species': 'Species'
    })
    df['Species'] = df['Species'].str.capitalize()
except ImportError:
    # Fallback: load from local CSV if palmerpenguins not installed
    df = pd.read_csv('images/classification/penguins.csv')
    df['Species'] = df['Species'].str.split(' ').str[0]

# Show first few rows
df[['Species', 'Flipper Length (mm)', 'Culmen Length (mm)']].head(10)
```

:::

## Visualizing the Data

How can we classify these?  (What do you think?)

:::{style="font-size: .7em"}

```{python}
#| echo: false
#| fig-align: center

fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Flipper length by species
for species in df['Species'].unique():
    data = df[df['Species'] == species]['Flipper Length (mm)'].dropna()
    axes[0].hist(data, alpha=0.6, label=species, bins=15)
axes[0].set_xlabel('Flipper Length (mm)', size=12)
axes[0].set_ylabel('Count', size=12)
axes[0].set_title('Flipper Length by Species', size=14)
axes[0].legend()

# Culmen length by species
for species in df['Species'].unique():
    data = df[df['Species'] == species]['Culmen Length (mm)'].dropna()
    axes[1].hist(data, alpha=0.6, label=species, bins=15)
axes[1].set_xlabel('Culmen Length (mm)', size=12)
axes[1].set_ylabel('Count', size=12)
axes[1].set_title('Culmen Length by Species', size=14)
axes[1].legend()

plt.tight_layout()
plt.show()
```

:::

## The Bayesian Approach

:::{style="font-size: .8em"}

We're going to build a Naive Bayes Classifier using our usual approach:


1. **Prior:** What do we believe before seeing any data?
   - P(Adélie), P(Chinstrap), P(Gentoo)


2. **Likelihood:** How likely is the observed data under each hypothesis?
   - P(flipper length = 193 mm | Adélie)
   - P(culmen length = 48 mm | Chinstrap)
   - etc.


3. **Posterior:** Update beliefs using Bayes' theorem
   - P(Adélie | data), P(Chinstrap | data), P(Gentoo | data)


4. **Decision:** Choose the class with highest posterior probability

:::

## Step 1: The Prior

:::{style="font-size: .8em"}

Without any measurements, all species are equally likely.

```{python}
# Create prior distribution
species_list = df['Species'].unique()
prior = pd.DataFrame(species_list, columns=['Species'])
prior['probs'] = 1/len(species_list)
prior
```


**Question: When might we want a non-uniform prior?**

If we knew we were in a region where Gentoo penguins are rare, we might set P(Gentoo) lower!


:::

## Alternative: Empirical Bayes

:::{style="font-size: .8em"}

Instead of a uniform prior, we could use the data itself to inform our prior!

```{python}
#| echo: true
species_counts = df['Species'].value_counts()
species_proportions = species_counts / species_counts.sum()
species_proportions
```


**Empirical Bayes approach:** Use these proportions as priors

```{python}
# Create empirical prior
prior_empirical = pd.DataFrame(species_list, columns=['Species'])
prior_empirical['probs'] = [species_proportions[sp] for sp in species_list]
prior_empirical
```

:::

## <span style="font-size: 0.7em">The Empirical Bayes Controversey</span>

:::{style="font-size: .7em"}

**The concern:** We're using the same data to set the prior AND update it!


::: {.columns}
::: {.column width="50%"}
**Less controversial when:**

- Using past data to inform priors
- Large datasets so prior has low impact
- Being transparent about the approach
- Domain knowledge supports the prior
:::

::: {.column width="50%"}
**More controversial when:**

- Using the exact same data twice
- Small datasets where prior matters
- Can lead to overconfidence
- Violates Bayesian "spirit"
:::
:::


**Our approach:** We'll use a uniform prior for this lecture (more conservative), but empirical Bayes is common in practice when you have lots of historical data!

:::

## <span style="font-size: 0.7em">Step 2: The Likelihood - Single Feature</span>

:::{style="font-size: .8em"}

For each species, we'll model flipper length as **normally distributed**.


**Key assumption:**
$$\text{Flipper length} \mid \text{Species} \sim \text{Normal}(\mu_{\text{species}}, \sigma_{\text{species}})$$


```{python}
def make_norm_map(df, colname, by='Species'):
    """Create normal distribution for each species based on data."""
    norm_map = {}
    grouped = df.groupby(by)[colname]
    for species, group in grouped:
        mean = group.mean()
        std = group.std()
        norm_map[species] = norm(mean, std)
    return norm_map

# Create distributions for flipper length
flipper_map = make_norm_map(df, 'Flipper Length (mm)')
```

:::

## <span style="font-size: 0.8em">Visualizing the Likelihood Models</span>

:::{style="font-size: .8em"}

```{python}
#| fig-width: 10
#| fig-height: 4
#| fig-align: center

x = np.linspace(170, 240, 300)
plt.figure(figsize=(10, 4))

for species in flipper_map.keys():
    y = flipper_map[species].pdf(x)
    plt.plot(x, y, label=species, linewidth=2)

plt.xlabel('Flipper Length (mm)', size=12)
plt.ylabel('Probability Density', size=12)
plt.title('Flipper Length Distributions by Species', size=14)
plt.legend()
plt.grid(alpha=0.3)
plt.show()
```

:::

## <span style="font-size: 0.8em">Likelihood for One Observation</span>

:::{style="font-size: .8em"}

**Observation:** Flipper length = 193 mm

```{python}
observed_flipper = 193

# Calculate likelihood for each species
likelihood = [flipper_map[species].pdf(observed_flipper)
              for species in species_list]

likelihood_df = pd.DataFrame({
    'Species': species_list,
    'Likelihood': likelihood
})
likelihood_df
```


Adélie and Chinstrap are most likely, Gentoo is very unlikely!

:::

## Step 3: The Update

:::{style="font-size: .8em"}

Apply Bayes' theorem to get the posterior:

$$P(\text{Species} \mid \text{data}) = \frac{P(\text{data} \mid \text{Species}) \cdot P(\text{Species})}{P(\text{data})}$$

```{python}
# Create comprehensive update table
update_table = pd.DataFrame({
    'Species': species_list,
    'Prior': prior['probs'].values,
    'Likelihood': likelihood,
})

# Calculate unnormalized posterior
update_table['Prior × Likelihood'] = update_table['Prior'] * update_table['Likelihood']

# Normalize to get posterior
normalizer = update_table['Prior × Likelihood'].sum()
update_table['Posterior'] = update_table['Prior × Likelihood'] / normalizer

update_table
```

:::

## Adding a Second Feature

:::{style="font-size: .8em"}

Flipper length alone doesn't distinguish Adélie from Chinstrap well.

Let's also use **culmen (beak) length**!

**Key idea:** The posterior from the first update becomes the prior for the second update!

```{python}
# Create distributions for culmen length
culmen_map = make_norm_map(df, 'Culmen Length (mm)')

# Observed culmen length
observed_culmen = 48

# Calculate likelihood for culmen length
likelihood_culmen = [culmen_map[species].pdf(observed_culmen)
                     for species in species_list]

# Create comprehensive update table
# The "Prior" here is actually the posterior from flipper length!
update_table_2 = pd.DataFrame({
    'Species': species_list,
    'Prior (from flipper)': update_table['Posterior'].values,
    'Likelihood (culmen)': likelihood_culmen,
})

# Calculate unnormalized posterior
update_table_2['Prior × Likelihood'] = update_table_2['Prior (from flipper)'] * update_table_2['Likelihood (culmen)']

# Normalize to get posterior
normalizer = update_table_2['Prior × Likelihood'].sum()
update_table_2['Posterior'] = update_table_2['Prior × Likelihood'] / normalizer

update_table_2
```


**Now we're confident:** It's a Chinstrap!

:::

## The "Naive" Assumption

:::{style="font-size: .8em"}

We just used two features **independently**:

1. Updated based on flipper length
2. Updated based on culmen length


**This assumes:** Flipper length and culmen length are **independent** given species

$$P(\text{flipper}, \text{culmen} \mid \text{species}) = P(\text{flipper} \mid \text{species}) \cdot P(\text{culmen} \mid \text{species})$$


**Is this true?**

Probably not! Larger penguins likely have both longer flippers AND longer beaks.

But... it often works surprisingly well anyway!


:::

## Why "Naive" Bayes Works

:::{style="font-size: .7em"}

Even though the independence assumption is violated, Naive Bayes often works well because:


1. **We only care about which class is most likely**, not exact probabilities
2. Even if correlations exist, they may be similar across classes
3. It's simple, fast, and works with many features
4. Less prone to overfitting than complex models


**Real-world success**

Naive Bayes achieves:

- 95%+ accuracy in spam detection
- 94.7% accuracy on our penguin dataset
- Competitive performance in many applications


:::

## Accounting for Correlations

:::{style="font-size: .8em"}

Instead of treating features independently, we can use a **multivariate normal distribution**.


**For each species:**

- **Mean vector:** $\boldsymbol{\mu} = [\mu_{\text{flipper}}, \mu_{\text{culmen}}]$
- **Covariance matrix:** $\boldsymbol{\Sigma}$ captures variances AND correlations


$$\begin{bmatrix} \text{Flipper Length} \\ \text{Culmen Length} \end{bmatrix} \mid \text{Species} \sim \text{MVN}(\boldsymbol{\mu}, \boldsymbol{\Sigma})$$

:::

## Visualizing the Covariance

:::{style="font-size: .8em"}

```{python}
#| fig-width: 10
#| fig-height: 5
#| fig-align: center

# Plot scatter for each species
fig, ax = plt.subplots(figsize=(10, 6))

for species in species_list:
    species_data = df[df['Species'] == species]
    ax.scatter(species_data['Flipper Length (mm)'],
               species_data['Culmen Length (mm)'],
               label=species, alpha=0.6, s=50)

ax.set_xlabel('Flipper Length (mm)', size=12)
ax.set_ylabel('Culmen Length (mm)', size=12)
ax.set_title('Flipper vs Culmen Length (Notice the correlation!)', size=14)
ax.legend()
ax.grid(alpha=0.3)
plt.show()
```


Notice: Longer flippers tend to go with longer beaks!


:::

## <span style="font-size: 0.9em">Computing Mean and Covariance</span>

:::{style="font-size: .8em"}

```{python}
# For Chinstrap penguins
chinstrap_data = df[df['Species'] == 'Chinstrap'][['Flipper Length (mm)',
                                                      'Culmen Length (mm)']].dropna()

# Mean vector
mean_chinstrap = chinstrap_data.mean()
print("Mean vector:")
print(mean_chinstrap)
print()

# Covariance matrix
cov_chinstrap = chinstrap_data.cov()
print("Covariance matrix:")
print(cov_chinstrap)
```


Off-diagonal elements (50.8) show positive correlation between features!
:::

## <span style="font-size: 0.7em">Defining our Multivariate Normals</span>

:::{style="font-size: .8em"}

```{python}
#| echo: true
def make_multinorm_map(df, colnames):
    multinorm_map = {}
    grouped = df.groupby('Species')
    for species, group in grouped:
        features = group[colnames].dropna()
        mean = features.mean()
        cov = features.cov()
        multinorm_map[species] = multivariate_normal(mean, cov)
    return multinorm_map

# Create multivariate normals
features = ['Flipper Length (mm)', 'Culmen Length (mm)']
multinorm_map = make_multinorm_map(df, features)
```


:::

## <span style="font-size: 0.7em">Classification with Multivariate Normal</span>

:::{style="font-size: .8em"}

Now we update **once** with both features together:
```{python}
#| echo: false
# Reset prior
prior = pd.DataFrame(species_list, columns=['Species'])
prior['probs'] = 1/len(species_list)
```

```{python}
#| echo: true
# Observed data: flipper = 193, culmen = 48
observed_data = [193, 48]

# Calculate likelihood for each species
likelihood_mv = [multinorm_map[species].pdf(observed_data)
                 for species in species_list]

# Update
posterior_mv = prior.copy()
update(posterior_mv, likelihood_mv)
posterior_mv
```


Still clearly Chinstrap, but probabilities are different!

:::


## <span style="font-size: 0.7em">Visualizing Decision Boundaries</span>

:::{style="font-size: .8em"}

```{python}
#| fig-width: 10
#| fig-height: 6
#| echo: false
#| fig-align: center

def classify_naive_bayes(row, flipper_map, culmen_map, species_list):
    """Classify using naive Bayes."""
    # Start with uniform prior
    probs = np.ones(len(species_list)) / len(species_list)

    # Update with flipper length
    flipper_likes = [flipper_map[sp].pdf(row['Flipper Length (mm)'])
                     for sp in species_list]
    probs = probs * flipper_likes

    # Update with culmen length
    culmen_likes = [culmen_map[sp].pdf(row['Culmen Length (mm)'])
                   for sp in species_list]
    probs = probs * culmen_likes

    # Normalize and return most likely species
    probs = probs / probs.sum()
    return species_list[np.argmax(probs)]

def classify_multivariate(row, multinorm_map, species_list):
    """Classify using multivariate normal."""
    data = [row['Flipper Length (mm)'], row['Culmen Length (mm)']]
    probs = [multinorm_map[sp].pdf(data) for sp in species_list]
    return species_list[np.argmax(probs)]

# Remove rows with missing data
df_clean = df.dropna(subset=['Flipper Length (mm)', 'Culmen Length (mm)'])

# Create a grid of points
flipper_range = np.linspace(df['Flipper Length (mm)'].min() - 5,
                            df['Flipper Length (mm)'].max() + 5, 100)
culmen_range = np.linspace(df['Culmen Length (mm)'].min() - 2,
                           df['Culmen Length (mm)'].max() + 2, 100)
flipper_grid, culmen_grid = np.meshgrid(flipper_range, culmen_range)

# Classify each grid point with multivariate normal
predictions = np.zeros(flipper_grid.shape)
for i in range(flipper_grid.shape[0]):
    for j in range(flipper_grid.shape[1]):
        data = [flipper_grid[i,j], culmen_grid[i,j]]
        probs = [multinorm_map[sp].pdf(data) for sp in species_list]
        predictions[i,j] = np.argmax(probs)

# Plot
fig, ax = plt.subplots(figsize=(10, 6))
ax.contourf(flipper_grid, culmen_grid, predictions, alpha=0.3, levels=2)

# Overlay actual data
for idx, species in enumerate(species_list):
    species_data = df_clean[df_clean['Species'] == species]
    ax.scatter(species_data['Flipper Length (mm)'],
               species_data['Culmen Length (mm)'],
               label=species, s=50, edgecolors='black', linewidths=0.5)

ax.set_xlabel('Flipper Length (mm)', size=12)
ax.set_ylabel('Culmen Length (mm)', size=12)
ax.set_title('Decision Boundaries (Multivariate Normal Classifier)', size=14)
ax.legend()
ax.grid(alpha=0.3)
plt.show()
```

:::



## <span style="font-size: 0.7em">Naive Bayes vs Multivariate Normal</span>

:::{style="font-size: .8em"}

```{python}
#| echo: false

comparison = pd.DataFrame({
    'Species': species_list,
    'Naive Bayes': [0.003455, 0.001246, 0.995299],
    'Multivariate Normal': posterior_mv['probs'].values
})
print(comparison.to_string(index=False))
```


**Performance on full dataset:**

- Naive Bayes: **94.7% accuracy**
- Multivariate Normal: **95.3% accuracy**

Multivariate normal is only slightly better! The correlation structure doesn't help much for this problem.


:::

## When to Use Which?

:::{style="font-size: .8em"}

::: {.columns}
::: {.column width="50%"}
**Naive Bayes**

- Many features
- Features might not be continuous
- Limited data
- Need speed/simplicity
- Text classification
:::

::: {.column width="50%"}
**Multivariate Normal**

- Continuous features
- Known correlations matter
- Enough data for covariance
- Need probability calibration
- Fewer features (<10-20)
:::
:::

Start with Naive Bayes! It's surprisingly effective and much simpler.

:::


## <span style="font-size: 0.8em">Group Question: Spam Detection</span>

:::{style="font-size: .6em"}

```{python}
from IPython.core.display import HTML

def generate_html():
    return r"""
    <div class="blue-box">
        <p>
<b>The Setup:</b> You want to determine if a text you receive is spam.  You've made the following observations:</b><br>
• 50% of your spam texts offer you a "job opportunity" (vs 1% of your regular texts) <br>
• 50% of your spam messages ask you do "donate" to something (vs 1% of your regular texts) <br>
• 20% of your real messages mention your name (vs 1% of the spam texts) <br>
• 10% of the texts you receive have spam <br>
<br><br>
<b>Your Task:</b> You just received the text: "Hi [your name] do you want to donate to my fundraiser?"  Using a Naive Bayes approach, make your best guess as to whether the text is spam or not.
        </p>
    </div>
    """
html_content = generate_html()
display(HTML(html_content))
```


:::
